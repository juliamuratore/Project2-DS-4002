{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../DATA/data.csv')\n",
    "data.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Min Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time series\n",
    "plt.plot(data['min_temp'])\n",
    "plt.title('Daily Min Temperature in Charlottesville, VA')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding parameters\n",
    "plot_acf(data['min_temp'], lags=40)\n",
    "plot_pacf(data['min_temp'], lags=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the ARIMA model\n",
    "model = ARIMA(data['min_temp'], order=(2, 0, 0))\n",
    "model_fit = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and forecast\n",
    "forecast = model_fit.get_forecast(steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data into train and test\n",
    "train_size = int(len(data) * 0.8)\n",
    "train, test = data[0:train_size], data[train_size:len(data)]\n",
    "\n",
    "# Fit the ARIMA model on the training dataset\n",
    "model_train = ARIMA(train['min_temp'], order=(2,0,0))\n",
    "model_train_fit = model_train.fit()\n",
    "\n",
    "# Forecast on the test dataset\n",
    "test_forecast = model_train_fit.get_forecast(steps=len(test))\n",
    "test_forecast_series = pd.Series(test_forecast.predicted_mean, index=test.index)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(test['min_temp'], test_forecast_series)\n",
    "min_temp_rmse = mse**0.5\n",
    "\n",
    "# Create a plot to compare the forecast with the actual test data\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.plot(train['min_temp'], label='Training Data')\n",
    "plt.plot(test['min_temp'], label='Actual Data', color='orange')\n",
    "plt.plot(test_forecast_series, label='Forecasted Data', color='green')\n",
    "plt.fill_between(test.index, \n",
    "                 test_forecast.conf_int().iloc[:, 0], \n",
    "                 test_forecast.conf_int().iloc[:, 1], \n",
    "                 color='k', alpha=.15)\n",
    "plt.title('ARIMA Model Evaluation')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Minimum Temp')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('RMSE:', min_temp_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(data['max_temp'], lags=40)\n",
    "plot_pacf(data['max_temp'], lags=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the ARIMA model\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "model = ARIMA(data['max_temp'], order=(2,0,0))\n",
    "model_fit = model.fit()\n",
    "\n",
    "# training and forecast\n",
    "forecast = model_fit.get_forecast(steps=30)\n",
    "\n",
    "# model evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data into train and test\n",
    "train_size = int(len(data) * 0.8)\n",
    "train, test = data[0:train_size], data[train_size:len(data)]\n",
    "\n",
    "# Fit the ARIMA model on the training dataset\n",
    "model_train = ARIMA(train['max_temp'], order=(2,0,0))\n",
    "model_train_fit = model_train.fit()\n",
    "\n",
    "# Forecast on the test dataset\n",
    "test_forecast = model_train_fit.get_forecast(steps=len(test))\n",
    "test_forecast_series = pd.Series(test_forecast.predicted_mean, index=test.index)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(test['min_temp'], test_forecast_series)\n",
    "max_temp_rmse = mse**0.5\n",
    "\n",
    "# Create a plot to compare the forecast with the actual test data\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.plot(train['max_temp'], label='Training Data')\n",
    "plt.plot(test['max_temp'], label='Actual Data', color='orange')\n",
    "plt.plot(test_forecast_series, label='Forecasted Data', color='green')\n",
    "plt.fill_between(test.index, \n",
    "                 test_forecast.conf_int().iloc[:, 0], \n",
    "                 test_forecast.conf_int().iloc[:, 1], \n",
    "                 color='k', alpha=.15)\n",
    "plt.title('ARIMA Model Evaluation')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Maximum Temp')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('RMSE:', max_temp_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sunrise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time series\n",
    "plt.plot(data['sunrise'])\n",
    "plt.title('Daily Sunrise in Charlottesville, VA')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding parameters\n",
    "plot_acf(data['sunrise'], lags=40)\n",
    "plot_pacf(data['sunrise'], lags=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the ARIMA model\n",
    "model = ARIMA(data['sunrise'], order=(1,0,1))\n",
    "model_fit = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and forecast\n",
    "forecast = model_fit.get_forecast(steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "\n",
    "# Split the data into train and test\n",
    "train_size = int(len(data) * 0.8)\n",
    "train, test = data[0:train_size], data[train_size:len(data)]\n",
    "\n",
    "# Fit the ARIMA model on the training dataset\n",
    "model_train = ARIMA(train['total_precip'], order=(1, 0, 1))\n",
    "model_train_fit = model_train.fit()\n",
    "\n",
    "# Forecast on the test dataset\n",
    "test_forecast = model_train_fit.get_forecast(steps=len(test))\n",
    "test_forecast_series = pd.Series(test_forecast.predicted_mean, index=test.index)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(test['total_precip'], test_forecast_series)\n",
    "sunrise_rmse = mse**0.5\n",
    "\n",
    "# Create a plot to compare the forecast with the actual test data\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.plot(train['total_precip'], label='Training Data')\n",
    "plt.plot(test['total_precip'], label='Actual Data', color='orange')\n",
    "plt.plot(test_forecast_series, label='Forecasted Data', color='green')\n",
    "plt.fill_between(test.index, \n",
    "                 test_forecast.conf_int().iloc[:, 0], \n",
    "                 test_forecast.conf_int().iloc[:, 1], \n",
    "                 color='k', alpha=.15)\n",
    "plt.title('ARIMA Model Evaluation')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Precipitation')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('RMSE:', sunrise_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hours of Daylight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daylight Time Series\n",
    "plt.plot(data['daylight'])\n",
    "plt.title('Total Hours of Daylight in Charlottesville, VA')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADF Fuller test: checking for stationarity\n",
    "adf_test = adfuller(data['daylight'])\n",
    "# Output the results\n",
    "print('ADF Statistic: %f' % adf_test[0])\n",
    "print('p-value: %f' % adf_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stationarity found: no need to difference it\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "plot_acf(data['daylight'], lags=40)\n",
    "plot_pacf(data['daylight'], lags=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining p, q, and d\n",
    "ACF model decays gradually: indicates p,d,0 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the ARIMA\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "model = ARIMA(data['daylight'], order=(1, 1, 0))\n",
    "model_fit = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Forecasting\n",
    "forecast = model_fit.get_forecast(steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data into train and test\n",
    "train_size = int(len(data) * 0.8)\n",
    "train, test = data[0:train_size], data[train_size:len(data)]\n",
    "\n",
    "# Fit the ARIMA model on the training dataset\n",
    "model_train = ARIMA(train['daylight'], order=(1, 0, 1))\n",
    "model_train_fit = model_train.fit()\n",
    "\n",
    "# Forecast on the test dataset\n",
    "test_forecast = model_train_fit.get_forecast(steps=len(test))\n",
    "test_forecast_series = pd.Series(test_forecast.predicted_mean, index=test.index)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(test['daylight'], test_forecast_series)\n",
    "rmse = mse**0.5\n",
    "\n",
    "# Create a plot to compare the forecast with the actual test data\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.plot(train['daylight'], label='Training Data')\n",
    "plt.plot(test['daylight'], label='Actual Data', color='orange')\n",
    "plt.plot(test_forecast_series, label='Forecasted Data', color='green')\n",
    "plt.fill_between(test.index, \n",
    "                 test_forecast.conf_int().iloc[:, 0], \n",
    "                 test_forecast.conf_int().iloc[:, 1], \n",
    "                 color='k', alpha=.15)\n",
    "plt.title('ARIMA Model Evaluation')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Hours of Daylight')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hours of Sunshine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daylight Time Series\n",
    "plt.plot(data['sunshine'])\n",
    "plt.title('Total Hours of Sunshine in Charlottesville, VA')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADF Fuller test: checking for stationarity\n",
    "adf_test = adfuller(data['sunshine'])\n",
    "# Output the results\n",
    "print('ADF Statistic: %f' % adf_test[0])\n",
    "print('p-value: %f' % adf_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stationarity found: no need to difference it\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "plot_acf(data['sunshine'], lags=40)\n",
    "plot_pacf(data['sunshine'], lags=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining p, q, and d\n",
    "ACF model decays gradually: indicates p,d,0 model\n",
    "Lag 2 is closest to the dense part of the PACF graph, so our p is lag 1 (by doing n-1).\n",
    "Order: (1,1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the ARIMA\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "model = ARIMA(data['sunshine'], order=(1, 1, 0))\n",
    "model_fit = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Forecasting\n",
    "forecast = model_fit.get_forecast(steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data into train and test\n",
    "train_size = int(len(data) * 0.8)\n",
    "train, test = data[0:train_size], data[train_size:len(data)]\n",
    "\n",
    "# Fit the ARIMA model on the training dataset\n",
    "model_train = ARIMA(train['sunshine'], order=(1, 0, 1))\n",
    "model_train_fit = model_train.fit()\n",
    "\n",
    "# Forecast on the test dataset\n",
    "test_forecast = model_train_fit.get_forecast(steps=len(test))\n",
    "test_forecast_series = pd.Series(test_forecast.predicted_mean, index=test.index)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(test['sunshine'], test_forecast_series)\n",
    "rmse = mse**0.5\n",
    "\n",
    "# Create a plot to compare the forecast with the actual test data\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.plot(train['sunshine'], label='Training Data')\n",
    "plt.plot(test['sunshine'], label='Actual Data', color='orange')\n",
    "plt.plot(test_forecast_series, label='Forecasted Data', color='green')\n",
    "plt.fill_between(test.index, \n",
    "                 test_forecast.conf_int().iloc[:, 0], \n",
    "                 test_forecast.conf_int().iloc[:, 1], \n",
    "                 color='k', alpha=.15)\n",
    "plt.title('ARIMA Model Evaluation')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Hours of Sunshine')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('RMSE:', rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
